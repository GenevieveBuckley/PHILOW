{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T61bVGE2VY5-"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/neurobiology-ut/PHILOW/blob/develop/notebooks/train_and_pred_using_PHILOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80fvsWpAVY6A"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2du4BfqVY6B"
   },
   "outputs": [],
   "source": [
    "def normalize_x(image):\n",
    "    return image / 127.5 - 1\n",
    "\n",
    "\n",
    "def normalize_y(image):\n",
    "    return image / 255\n",
    "\n",
    "\n",
    "def denormalize_y(image):\n",
    "    return image * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVMymY7VVY6B"
   },
   "outputs": [],
   "source": [
    "def load_X_gray(folder_path):\n",
    "    \n",
    "    image_files = []       \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1), np.float32)\n",
    "    for i, image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        images[i] = normalize_x(image)\n",
    "    \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images, image_files\n",
    "\n",
    "\n",
    "def load_Y_gray(folder_path, thresh = None , normalize = False):\n",
    "    \n",
    "    image_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1) ,np.float32)\n",
    "    \n",
    "    for i , image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        if thresh:\n",
    "            ret , image = cv2.threshold(image , thresh , 255 , cv2.THRESH_BINARY)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        if normalize:\n",
    "            images[i] = normalize_y(image)\n",
    "        else:\n",
    "            images[i] = image\n",
    "            \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FQQ_NyIakf-"
   },
   "outputs": [],
   "source": [
    "def select_train_data(dataframe, ori_imgs, label_imgs, ori_filenames, label_filenames):\n",
    "\n",
    "  train_img_names = list()\n",
    "  for node in dataframe.itertuples():\n",
    "    if node.train == \"Checked\":\n",
    "      train_img_names.append(node.filename)\n",
    "\n",
    "  train_ori_imgs = list()\n",
    "  train_label_imgs = list()\n",
    "  for ori_img, label_img, train_filename in zip(ori_imgs, label_imgs, ori_filenames):\n",
    "    if train_filename in train_img_names:\n",
    "      train_ori_imgs.append(ori_img)\n",
    "      train_label_imgs.append(label_img)\n",
    "\n",
    "  return np.array(train_ori_imgs),  np.array(train_label_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_imgs(images):\n",
    "    \n",
    "    H = -(-images.shape[1]//412)\n",
    "    W = -(-images.shape[2]//412)\n",
    "    \n",
    "    diveded_imgs = np.zeros(( images.shape[0]*H*W, 512, 512, 1), np.float32)\n",
    "    print(H,W)\n",
    "    \n",
    "    for z in range(images.shape[0]):\n",
    "        image = images[z]\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "                cropped_img = np.zeros((512, 512, 1), np.float32)\n",
    "                cropped_img -= 1\n",
    "                \n",
    "                if images.shape[1] < 412:\n",
    "                    h = -1\n",
    "                if images.shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:images.shape[2]+50, 0] = image[0:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:images.shape[1]+50, 50:512, 0] = image[0:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:images.shape[1]+50, 0:images.shape[2]-412*W-50, 0] = image[0:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        cropped_img[50:images.shape[1]+50, :, 0] = image[0:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        cropped_img[50:512, 50:images.shape[2]+50, 0] = image[0:462, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[50:512, 50:512, 0] = image[0:462, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[50:512, 0:images.shape[2]-412*W-50, 0] = image[0:462, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[50:512, :, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[50:512, 0:images.shape[2]-412*(W-1)-50, 0] = image[0:462, w*412-50:(w+1)*412+50, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:images.shape[2]+50, 0] = image[h*412-50:images.shape[1], 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 50:512, 0] = image[h*412-50:images.shape[1], 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:images.shape[1], w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        try:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, :, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:images.shape[1], w*412-50:(w+1)*412+50, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                        cropped_img[:, 50:images.shape[2]+50, 0] = image[h*412-50:(h+1)*412+50, 0:images.shape[2], 0]\n",
    "                    elif w == 0:\n",
    "                        #cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 50:512, 0] = image[h*412-50:(h+1)*412+50, 0:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        #cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        try:\n",
    "                            cropped_img[:, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                        except:\n",
    "                            cropped_img[0:images.shape[1]-412*H-50+412, 0:images.shape[2]-412*W-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:images.shape[2], 0]\n",
    "                    else:\n",
    "                        #cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                        try:\n",
    "                            cropped_img[:, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]         \n",
    "                        except:\n",
    "                            try:\n",
    "                                 cropped_img[:, 0:images.shape[2]-412*(W-1)-50, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                            except:\n",
    "                                 cropped_img[0:images.shape[1]-412*(H-1)-50, :, 0] = image[h*412-50:(h+1)*412+50, w*412-50:(w+1)*412+50, 0]\n",
    "                h = max(0, h)\n",
    "                w = max(0, w)\n",
    "                diveded_imgs[z*H*W+ w*H+h] = cropped_img\n",
    "                #print(z*H*W+ w*H+h)\n",
    "                \n",
    "    return diveded_imgs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def merge_imgs(imgs, original_image_shape):\n",
    "    \n",
    "    merged_imgs = np.zeros((original_image_shape[0], original_image_shape[1], original_image_shape[2], 1), np.float32)\n",
    "    H = -(-original_image_shape[1]//412)\n",
    "    W = -(-original_image_shape[2]//412)    \n",
    "    \n",
    "    for z in range(original_image_shape[0]):\n",
    "        for h in range(H):\n",
    "            for w in range(W):\n",
    "\n",
    "                if original_image_shape[1] < 412:\n",
    "                    h = -1\n",
    "                if original_image_shape[2] < 412:\n",
    "                    w = -1\n",
    "                    \n",
    "                #print(z*H*W+ max(w, 0)*H+max(h, 0))    \n",
    "                if h == -1:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+0][50:original_image_shape[1]+50, 50:462, 0]\n",
    "                elif h == 0:\n",
    "                    if w == -1:\n",
    "                        merged_imgs[z, 0:412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, 0:412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, 0:412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, 0:412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                elif h == H-1:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:original_image_shape[1], 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], 0:412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:original_image_shape[1], w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:original_image_shape[1]-412*H-50, 50:462, 0]\n",
    "                else:\n",
    "                    if w == -1:\n",
    "                         merged_imgs[z, h*412:(h+1)*412, 0:original_image_shape[2], 0] = imgs[z*H*W+ 0*H+h][50:462, 50:original_image_shape[2]+50, 0]\n",
    "                    elif w == 0:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, 0:412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]\n",
    "                    elif w == W-1:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:original_image_shape[2], 0] = imgs[z*H*W+ w*H+h][50:462, 50:original_image_shape[2]-412*W-50, 0]\n",
    "                    else:\n",
    "                        merged_imgs[z, h*412:(h+1)*412, w*412:(w+1)*412, 0] = imgs[z*H*W+ w*H+h][50:462, 50:462, 0]  \n",
    "        \n",
    "    print(merged_imgs.shape)\n",
    "    return merged_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5Arj00hVY6C"
   },
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_dice_coeff(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                          (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWJPMR1WVY6E"
   },
   "outputs": [],
   "source": [
    "def standard_uint(input_tensor, nb_filter):\n",
    "    \n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_nested_unet(input_shape=(512, 512, 1), num_classes=3, deep_supervision = False):\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        \n",
    "        inputs = Input(shape = input_shape)\n",
    "        \n",
    "        # 512\n",
    "        conv1_1 = standard_uint(inputs, nb_filter = 16)\n",
    "        pool1 = MaxPooling2D((2, 2), strides = (2, 2))(conv1_1)\n",
    "        \n",
    "        #256\n",
    "        conv2_1 = standard_uint(pool1, nb_filter = 32)\n",
    "        pool2 = MaxPooling2D((2, 2), strides = (2, 2))(conv2_1)\n",
    "        \n",
    "        up1_2 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], axis = 3)\n",
    "        conv1_2 = standard_uint(conv1_2, nb_filter = 16)\n",
    "        \n",
    "        #128\n",
    "        conv3_1 = standard_uint(pool2, nb_filter = 64)\n",
    "        pool3 = MaxPooling2D((2, 2), strides = (2, 2))(conv3_1)\n",
    "        \n",
    "        up2_2 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], axis = 3)\n",
    "        conv2_2 = standard_uint(conv2_2, nb_filter = 32)\n",
    "        \n",
    "        up1_3 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], axis = 3)\n",
    "        conv1_3 = standard_uint(conv1_3, nb_filter = 16)\n",
    "        \n",
    "        # 64\n",
    "        conv4_1 = standard_uint(pool3, nb_filter = 128)\n",
    "        pool4 = MaxPooling2D((2, 2), strides = (2, 2))(conv4_1)      \n",
    "        \n",
    "        up3_2 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], axis = 3)\n",
    "        conv3_2 = standard_uint(conv3_2, nb_filter = 64)    \n",
    "        \n",
    "        up2_3 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], axis = 3)\n",
    "        conv2_3 = standard_uint(conv2_3, nb_filter = 32)        \n",
    "        \n",
    "        up1_4 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_2, conv1_3], axis = 3)\n",
    "        conv1_4 = standard_uint(conv1_4, nb_filter = 16)       \n",
    "        \n",
    "        # 32\n",
    "        conv5_1 = standard_uint(pool4, nb_filter = 256)    \n",
    "        \n",
    "        up4_2 = Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], axis = 3)\n",
    "        conv4_2 = standard_uint(conv4_2, nb_filter = 128)  \n",
    "        \n",
    "        up3_3 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], axis = 3)\n",
    "        conv3_3 = standard_uint(conv3_3, nb_filter = 64)\n",
    "        \n",
    "        up2_4 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], axis = 3)\n",
    "        conv2_4 = standard_uint(conv2_4, nb_filter = 32)\n",
    "        \n",
    "        up1_5 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], axis = 3)\n",
    "        conv1_5 = standard_uint(conv1_5, nb_filter = 16)\n",
    "        \n",
    "        nested_output_1 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_2)\n",
    "        nested_output_2 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_3)\n",
    "        nested_output_3 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_4)\n",
    "        nested_output_4 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_5)\n",
    "        \n",
    "        if deep_supervision:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_1, nested_output_2, nested_output_3, nested_output_4]) \n",
    "        else:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_4])\n",
    "            \n",
    "        model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4V3xJKemVY6G"
   },
   "outputs": [],
   "source": [
    "def train_unet(X_train,Y_train, csv_path, model_path ,input_shape=(512, 512, 1), num_classes=1):\n",
    "    Y_train = Y_train\n",
    "    X_train = X_train\n",
    "\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=90.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    mask_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_train, seed=seed, batch_size=8)\n",
    "    mask_generator = mask_datagen.flow(Y_train, seed=seed, batch_size=8)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = (pair for pair in zip(image_generator, mask_generator))\n",
    "\n",
    "    model = get_nested_unet(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCH = 400\n",
    "    \n",
    "    callbacks = []\n",
    "    from tensorflow.keras.callbacks import CSVLogger\n",
    "    callbacks.append(CSVLogger(csv_path))\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=32, epochs=NUM_EPOCH, verbose=1, callbacks=callbacks)\n",
    "    model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TuuQDD6UHJN1"
   },
   "outputs": [],
   "source": [
    "def predict(X_test, model_path, out_dir, input_shape=(512, 512, 1), num_classes=1):\n",
    "\n",
    "    model = get_nested_unet(input_shape=input_shape, num_classes=num_classes)\n",
    "    \n",
    "    model.load_weights(model_path)\n",
    "    BATCH_SIZE = 1\n",
    "    Y_pred = model.predict(X_test, BATCH_SIZE)\n",
    "    \n",
    "    print(Y_pred.shape)\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "    \n",
    "    if Y_pred.shape[3]!=1:\n",
    "        num = Y_pred.shape[3]\n",
    "        for n in range(num):\n",
    "            os.makedirs(os.path.join(out_dir,str(n+1)), exist_ok=True)\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            for n in range(num):\n",
    "                cv2.imwrite(os.path.join(out_dir, str(n+1) , str(i).zfill(6) + '.png'), denormalize_y(y[:,:,n]))\n",
    "        \n",
    "    else:\n",
    "        for i, y in enumerate(Y_pred):\n",
    "            cv2.imwrite(os.path.join(out_dir , str(i).zfill(6) + '.png'), denormalize_y(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VGWEl0CKoTO"
   },
   "outputs": [],
   "source": [
    "def make_mask_img(ori_img, mask_img):\n",
    "    mask_img_rgb = np.zeros((mask_img.shape[0], mask_img.shape[1], 3), np.float32)\n",
    "    mask_img_rgb[:,:,0] = mask_img[:,:,0]\n",
    "    mask_img_rgb[:,:,2] = mask_img[:,:,0]\n",
    "    masked_img = cv2.addWeighted(mask_img_rgb,0.5,cv2.cvtColor(ori_img+0.75, cv2.COLOR_GRAY2BGR),0.6,0)\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIq0ZPZcJKzl"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giKZr1_KVeLe",
    "outputId": "97a153cc-a6ff-4e78-fe62-69192e558480"
   },
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "gdd.download_file_from_google_drive(file_id='1xM0mqK3pA84CuGcK372EY1wt-WiBkm56',\n",
    "                                    dest_path='./data.zip',\n",
    "                                    unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "2372a939a8564fd6be916b31a31836be",
      "10e73d35bf904cf5935f9444de95e49d",
      "c4a961259c2d4f749f72bd8da6cc832e",
      "ef75d37fbb2843209c826d50fa01f8e3",
      "c3dcbcc48add42e0a8fd9fb99119fbad",
      "6711140293a74db486a73f2f967f3ffc",
      "f6822586f855471ba06c88e37b129950",
      "09b8f5053aa846ce8d99dc61a42bdd29",
      "dd116406dab24904b88535ee186b8578",
      "d792c87844044b21a91c6914efeba298",
      "8d897f0fe9744f0f93a61d474e8dca48",
      "4518de682e8f4dd8be16b43fc523b777",
      "e249762ffaf242fd904d9b3f46d6909e",
      "e07bf1affe19486caaa3c88560f8d948",
      "194e21d040744463b1d693c6ca95b776",
      "b684212c71524861b6024ab3f5ec802a"
     ]
    },
    "id": "mRU_Xy1xZePB",
    "outputId": "8df74cf8-90d1-4961-c730-78f47e0917e2"
   },
   "outputs": [],
   "source": [
    "ori_imgs, ori_filenames = load_X_gray(\"./PHILOW_demo_data/ori\")\n",
    "label_imgs, label_filenames = load_Y_gray(\"./PHILOW_demo_data/label\", normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXhE0V07Z8zt"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"./PHILOW_demo_data/label/_train0.csv\", index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s34WM6KUaZ7f"
   },
   "outputs": [],
   "source": [
    "train_ori_imgs, train_label_imgs = select_train_data(\n",
    "    dataframe = train_csv, \n",
    "    ori_imgs  = ori_imgs, \n",
    "    label_imgs = label_imgs, \n",
    "    ori_filenames = ori_filenames,\n",
    "    label_filenames = label_filenames\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "id": "1VqhNx-y62jT",
    "outputId": "134293dd-b7ce-4e8a-ee33-50e12bfd4336"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(train_ori_imgs[4][:,:,0], \"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(train_label_imgs[4][:,:,0], \"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(train_ori_imgs[7][:,:,0], \"gray\")\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(train_label_imgs[7][:,:,0], \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYVBBKIp7Hwd",
    "outputId": "1c026991-fd66-4bb7-c2c4-96bf0b3198ad"
   },
   "outputs": [],
   "source": [
    "train_unet(\n",
    "    X_train = train_ori_imgs,\n",
    "    Y_train = train_label_imgs, \n",
    "    csv_path = \"train_log.csv\", \n",
    "    model_path = \"demo.hdf5\", \n",
    "    input_shape = (512, 512, 1),\n",
    "    num_classes = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skwNt3VEJOa8"
   },
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3ZAcBfYHyM3",
    "outputId": "85a9466f-95e3-4f5e-f081-a63860b2a7ca"
   },
   "outputs": [],
   "source": [
    "# XY\n",
    "seped_xy_imgs = divide_imgs(ori_imgs)\n",
    "\n",
    "predict(\n",
    "    X_test = seped_xy_imgs, \n",
    "    model_path = \"demo.hdf5\", \n",
    "    out_dir = \"./pred_xy\", \n",
    "    input_shape = (512, 512, 1), \n",
    "    num_classes = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YZ\n",
    "seped_yz_imgs = divide_imgs(ori_imgs.transpose(2, 0, 1, 3))\n",
    "\n",
    "predict(\n",
    "    X_test = seped_yz_imgs, \n",
    "    model_path = \"demo.hdf5\", \n",
    "    out_dir = \"./pred_yz\", \n",
    "    input_shape = (512, 512, 1), \n",
    "    num_classes = 1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZX\n",
    "seped_zx_imgs = divide_imgs(ori_imgs.transpose(1, 2, 0, 3))\n",
    "\n",
    "predict(\n",
    "    X_test = seped_zx_imgs, \n",
    "    model_path = \"demo.hdf5\", \n",
    "    out_dir = \"./pred_zx\", \n",
    "    input_shape = (512, 512, 1), \n",
    "    num_classes = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2j1iMjWSJRFP"
   },
   "source": [
    "# merge predict results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "c1d08f5321084414bfd44cc1ad884427",
      "770510627f284dc4bcd8371e3c6e2382",
      "e4890da3183944caaaa2945e515cac93",
      "b0b0c2fd6b5545dab194e08761b92a51",
      "3b36e850edf14dcdab2dda7c5aa5117a",
      "b33b49bfe2654e1bb5f6f80cf06eb230",
      "9c0ae4b8bfb24df798fcd201ee14b110",
      "0afd2ac0176947d7893559a2896afbf7"
     ]
    },
    "id": "cZzhm--ZJc73",
    "outputId": "bf3168c2-0d4f-42b8-8e0a-047cc34f2498"
   },
   "outputs": [],
   "source": [
    "ori_image_shape = ori_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "abjTLKv_Jl0A",
    "outputId": "baf9085f-9f1e-45c1-b036-499aaf7a543d"
   },
   "outputs": [],
   "source": [
    "pred_xy_imgs,_ = load_Y_gray(\"./pred_xy\")\n",
    "merged_imgs_xy = merge_imgs(pred_xy_imgs, ori_image_shape)\n",
    "\n",
    "pred_yz_imgs,_ = load_Y_gray(\"./pred_yz\")\n",
    "merged_imgs_yz = merge_imgs(pred_yz_imgs, (ori_image_shape[2], ori_image_shape[0], ori_image_shape[1], ori_image_shape[3]))\n",
    "\n",
    "pred_zx_imgs,_ = load_Y_gray(\"./pred_zx\")\n",
    "merged_imgs_zx = merge_imgs(pred_zx_imgs, (ori_image_shape[1], ori_image_shape[2], ori_image_shape[0], ori_image_shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kQaQ5NW9gzM"
   },
   "outputs": [],
   "source": [
    "mito_imgs_ave = merged_imgs_xy * 255 // 3 + merged_imgs_yz.transpose(1, 2, 0, 3) * 255 // 3 + merged_imgs_zx.transpose(2, 0, 1, 3) * 255 //3\n",
    "\n",
    "\n",
    "out_dir = './merged_prediction'\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "os.makedirs(f\"{out_dir}_raw\", exist_ok = True)\n",
    "\n",
    "\n",
    "for i in range(mito_imgs_ave.shape[0]):\n",
    "    \n",
    "    # threshed\n",
    "    img = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        1,\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}/{str(i).zfill(4)}.png', img)\n",
    "    \n",
    "    # averaged\n",
    "    img_ = np.where(\n",
    "        mito_imgs_ave[:,:,:,0][i] >= 127,\n",
    "        mito_imgs_ave[:,:,:,0][i],\n",
    "        0\n",
    "    )\n",
    "    cv2.imwrite(f'{out_dir}_raw/{str(i).zfill(4)}.png', img_)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09b8f5053aa846ce8d99dc61a42bdd29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afd2ac0176947d7893559a2896afbf7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e73d35bf904cf5935f9444de95e49d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "194e21d040744463b1d693c6ca95b776": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2372a939a8564fd6be916b31a31836be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4a961259c2d4f749f72bd8da6cc832e",
       "IPY_MODEL_ef75d37fbb2843209c826d50fa01f8e3"
      ],
      "layout": "IPY_MODEL_10e73d35bf904cf5935f9444de95e49d"
     }
    },
    "3b36e850edf14dcdab2dda7c5aa5117a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4518de682e8f4dd8be16b43fc523b777": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b684212c71524861b6024ab3f5ec802a",
      "placeholder": "​",
      "style": "IPY_MODEL_194e21d040744463b1d693c6ca95b776",
      "value": " 200/? [01:36&lt;00:00,  2.08it/s]"
     }
    },
    "6711140293a74db486a73f2f967f3ffc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "770510627f284dc4bcd8371e3c6e2382": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d897f0fe9744f0f93a61d474e8dca48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e07bf1affe19486caaa3c88560f8d948",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e249762ffaf242fd904d9b3f46d6909e",
      "value": 1
     }
    },
    "9c0ae4b8bfb24df798fcd201ee14b110": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0b0c2fd6b5545dab194e08761b92a51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0afd2ac0176947d7893559a2896afbf7",
      "placeholder": "​",
      "style": "IPY_MODEL_9c0ae4b8bfb24df798fcd201ee14b110",
      "value": " 200/? [00:00&lt;00:00, 500.68it/s]"
     }
    },
    "b33b49bfe2654e1bb5f6f80cf06eb230": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b684212c71524861b6024ab3f5ec802a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1d08f5321084414bfd44cc1ad884427": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4890da3183944caaaa2945e515cac93",
       "IPY_MODEL_b0b0c2fd6b5545dab194e08761b92a51"
      ],
      "layout": "IPY_MODEL_770510627f284dc4bcd8371e3c6e2382"
     }
    },
    "c3dcbcc48add42e0a8fd9fb99119fbad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c4a961259c2d4f749f72bd8da6cc832e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6711140293a74db486a73f2f967f3ffc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c3dcbcc48add42e0a8fd9fb99119fbad",
      "value": 1
     }
    },
    "d792c87844044b21a91c6914efeba298": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd116406dab24904b88535ee186b8578": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d897f0fe9744f0f93a61d474e8dca48",
       "IPY_MODEL_4518de682e8f4dd8be16b43fc523b777"
      ],
      "layout": "IPY_MODEL_d792c87844044b21a91c6914efeba298"
     }
    },
    "e07bf1affe19486caaa3c88560f8d948": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e249762ffaf242fd904d9b3f46d6909e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e4890da3183944caaaa2945e515cac93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b33b49bfe2654e1bb5f6f80cf06eb230",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b36e850edf14dcdab2dda7c5aa5117a",
      "value": 1
     }
    },
    "ef75d37fbb2843209c826d50fa01f8e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09b8f5053aa846ce8d99dc61a42bdd29",
      "placeholder": "​",
      "style": "IPY_MODEL_f6822586f855471ba06c88e37b129950",
      "value": " 200/? [00:00&lt;00:00, 250.22it/s]"
     }
    },
    "f6822586f855471ba06c88e37b129950": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
