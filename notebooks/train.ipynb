{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/neurobiology-ut/Philis/blob/feature/add_train_and_pred_notebooks/notebooks/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_x(image):\n",
    "    return image / 127.5 - 1\n",
    "\n",
    "\n",
    "def normalize_y(image):\n",
    "    return image / 255\n",
    "\n",
    "\n",
    "def denormalize_y(image):\n",
    "    return image * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_gray(folder_path):\n",
    "    \n",
    "    image_files = []       \n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else :\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1), np.float32)\n",
    "    for i, image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        images[i] = normalize_x(image)\n",
    "    \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images, image_files\n",
    "\n",
    "\n",
    "def load_Y_gray(folder_path, thresh = None , normalize = False):\n",
    "    \n",
    "    image_files = []\n",
    "    for file in os.listdir(folder_path):\n",
    "        base, ext = os.path.splitext(file)\n",
    "        if ext == '.png':\n",
    "            image_files.append(file)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    image_files.sort()\n",
    "    \n",
    "    img = cv2.imread(folder_path + os.sep + image_files[0], cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    images = np.zeros((len(image_files), img.shape[0], img.shape[1], 1) ,np.float32)\n",
    "    \n",
    "    for i , image_file in tqdm(enumerate(image_files)):\n",
    "        image = cv2.imread(folder_path + os.sep + image_file, cv2.IMREAD_GRAYSCALE)\n",
    "        if thresh:\n",
    "            ret , image = cv2.threshold(image , thresh , 255 , cv2.THRESH_BINARY)\n",
    "        image = image[:, :, np.newaxis]\n",
    "        if normalize:\n",
    "            images[i] = normalize_y(image)\n",
    "        else:\n",
    "            images[i] = image\n",
    "            \n",
    "    print(images.shape)\n",
    "    \n",
    "    return images, image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_dice_coeff(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = 1 - weighted_dice_coeff(y_true, y_pred, weight)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "                                          (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    if K.int_shape(y_pred)[1] == 128:\n",
    "        kernel_size = 11\n",
    "    elif K.int_shape(y_pred)[1] == 256:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 512:\n",
    "        kernel_size = 21\n",
    "    elif K.int_shape(y_pred)[1] == 1024:\n",
    "        kernel_size = 41\n",
    "    else:\n",
    "        raise ValueError('Unexpected image size')\n",
    "    averaged_mask = K.pool2d(\n",
    "        y_true, pool_size=(kernel_size, kernel_size), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.005), 'float32') * K.cast(K.less(averaged_mask, 0.995), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + (1 - weighted_dice_coeff(y_true, y_pred, weight))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_uint(input_tensor, nb_filter):\n",
    "    \n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def get_nested_unet(input_shape=(512, 512, 1), num_classes=3, deep_supervision = False):\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        \n",
    "        inputs = Input(shape = input_shape)\n",
    "        \n",
    "        # 512\n",
    "        conv1_1 = standard_uint(inputs, nb_filter = 16)\n",
    "        pool1 = MaxPooling2D((2, 2), strides = (2, 2))(conv1_1)\n",
    "        \n",
    "        #256\n",
    "        conv2_1 = standard_uint(pool1, nb_filter = 32)\n",
    "        pool2 = MaxPooling2D((2, 2), strides = (2, 2))(conv2_1)\n",
    "        \n",
    "        up1_2 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_1)\n",
    "        conv1_2 = concatenate([up1_2, conv1_1], axis = 3)\n",
    "        conv1_2 = standard_uint(conv1_2, nb_filter = 16)\n",
    "        \n",
    "        #128\n",
    "        conv3_1 = standard_uint(pool2, nb_filter = 64)\n",
    "        pool3 = MaxPooling2D((2, 2), strides = (2, 2))(conv3_1)\n",
    "        \n",
    "        up2_2 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_1)\n",
    "        conv2_2 = concatenate([up2_2, conv2_1], axis = 3)\n",
    "        conv2_2 = standard_uint(conv2_2, nb_filter = 32)\n",
    "        \n",
    "        up1_3 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_2)\n",
    "        conv1_3 = concatenate([up1_3, conv1_1, conv1_2], axis = 3)\n",
    "        conv1_3 = standard_uint(conv1_3, nb_filter = 16)\n",
    "        \n",
    "        # 64\n",
    "        conv4_1 = standard_uint(pool3, nb_filter = 128)\n",
    "        pool4 = MaxPooling2D((2, 2), strides = (2, 2))(conv4_1)      \n",
    "        \n",
    "        up3_2 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_1)\n",
    "        conv3_2 = concatenate([up3_2, conv3_1], axis = 3)\n",
    "        conv3_2 = standard_uint(conv3_2, nb_filter = 64)    \n",
    "        \n",
    "        up2_3 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_2)\n",
    "        conv2_3 = concatenate([up2_3, conv2_1, conv2_2], axis = 3)\n",
    "        conv2_3 = standard_uint(conv2_3, nb_filter = 32)        \n",
    "        \n",
    "        up1_4 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_3)\n",
    "        conv1_4 = concatenate([up1_4, conv1_2, conv1_3], axis = 3)\n",
    "        conv1_4 = standard_uint(conv1_4, nb_filter = 16)       \n",
    "        \n",
    "        # 32\n",
    "        conv5_1 = standard_uint(pool4, nb_filter = 256)    \n",
    "        \n",
    "        up4_2 = Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same')(conv5_1)\n",
    "        conv4_2 = concatenate([up4_2, conv4_1], axis = 3)\n",
    "        conv4_2 = standard_uint(conv4_2, nb_filter = 128)  \n",
    "        \n",
    "        up3_3 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(conv4_2)\n",
    "        conv3_3 = concatenate([up3_3, conv3_1, conv3_2], axis = 3)\n",
    "        conv3_3 = standard_uint(conv3_3, nb_filter = 64)\n",
    "        \n",
    "        up2_4 = Conv2DTranspose(32, (2, 2), strides = (2, 2), padding = 'same')(conv3_3)\n",
    "        conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], axis = 3)\n",
    "        conv2_4 = standard_uint(conv2_4, nb_filter = 32)\n",
    "        \n",
    "        up1_5 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(conv2_4)\n",
    "        conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], axis = 3)\n",
    "        conv1_5 = standard_uint(conv1_5, nb_filter = 16)\n",
    "        \n",
    "        nested_output_1 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_2)\n",
    "        nested_output_2 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_3)\n",
    "        nested_output_3 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_4)\n",
    "        nested_output_4 = Conv2D(num_classes, (1, 1), activation = 'sigmoid')(conv1_5)\n",
    "        \n",
    "        if deep_supervision:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_1, nested_output_2, nested_output_3, nested_output_4]) \n",
    "        else:\n",
    "            model = Model(inputs = inputs, outputs = [nested_output_4])\n",
    "            \n",
    "        model.compile(optimizer=RMSprop(lr=0.0001), loss=bce_dice_loss, metrics=[dice_coeff])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unet(X_train,Y_train, csv_path, model_path ,input_shape=(512, 512, 1), num_classes=1):\n",
    "    Y_train = Y_train\n",
    "    X_train = X_train\n",
    "\n",
    "    data_gen_args = dict(\n",
    "        rotation_range=90.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "    )\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    mask_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(X_train, seed=seed, batch_size=8)\n",
    "    mask_generator = mask_datagen.flow(Y_train, seed=seed, batch_size=8)\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = (pair for pair in zip(image_generator, mask_generator))\n",
    "\n",
    "    model = get_nested_unet(input_shape=input_shape, num_classes=num_classes)\n",
    "\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_EPOCH = 400\n",
    "    \n",
    "    callbacks = []\n",
    "    from tensorflow.keras.callbacks import CSVLogger\n",
    "    callbacks.append(CSVLogger(csv_path))\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=32, epochs=NUM_EPOCH, verbose=1, callbacks=callbacks)\n",
    "    model.save_weights(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
